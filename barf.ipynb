{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CometLogger\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from kornia.utils import create_meshgrid\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from einops import rearrange\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import OrderedDict\n",
    "from kornia.augmentation import RandomAffine, CenterCrop\n",
    "import cv2 as cv\n",
    "from utils import show\n",
    "from models import Homography, NeuralRenderer, SineLayer, Siren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords_dataloader(img):\n",
    "    C,H,W = img.size()\n",
    "    img = rearrange(img,'c H W -> (H W) c')\n",
    "\n",
    "    x = create_meshgrid(H,W).squeeze()\n",
    "    ones = torch.ones((H,W,1))\n",
    "    x_hom = torch.concat([x,ones], dim=2)\n",
    "    x_hom = rearrange(x_hom,'H W C -> (H W) C')\n",
    "    dataset  = TensorDataset(x_hom, img)\n",
    "    dataloader = DataLoader(dataset, batch_size=H*W)\n",
    "    return dataloader\n",
    "    \n",
    "\n",
    "class BARF_PL(pl.LightningModule):\n",
    "    def __init__(self, imgs, img_mask, img_GT, H_GT, pos_enc=False, L=10, barf_c2f = True, video_file = \"output.avi\"):\n",
    "        super().__init__()\n",
    "        #self.mlp = NeuralRenderer(True)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.L = L\n",
    "        self.pos_enc = pos_enc\n",
    "        self.barf_c2f = barf_c2f\n",
    "        if pos_enc:\n",
    "            input_size = 2*2*L\n",
    "        else:\n",
    "            input_size = 2\n",
    "        \n",
    "        # Reference Image with mask\n",
    "        self.mask = img_mask.cuda()\n",
    "        self.img = imgs[0]\n",
    "\n",
    "        # MLP-Model (SIREN)\n",
    "        self.mlp = Siren(in_features=input_size, out_features=3, hidden_features=256,\n",
    "                  hidden_layers=3, outermost_linear=True)\n",
    "        \n",
    "        # Loss\n",
    "        self.loss = nn.L1Loss()\n",
    "        self.H_loss = nn.MSELoss()\n",
    "\n",
    "        \n",
    "        # Images \n",
    "        self.imgs = imgs\n",
    "        img = self.img\n",
    "        C,H,W = self.img.size()\n",
    "        \n",
    "        \n",
    "        # Homographies\n",
    "        self.homographies = nn.ModuleList([Homography() for _ in imgs])\n",
    "\n",
    "        # Video Writer\n",
    "        self.out = cv.VideoWriter( video_file, cv.VideoWriter_fourcc('M','J','P','G'), 3, (W,H))\n",
    "        \n",
    "        # Ground Truth labels\n",
    "        self.homographies_GT = H_GT\n",
    "        self.img_GT = img_GT\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.clone().requires_grad_(True)\n",
    "        if self.pos_enc:\n",
    "            x = self.positional_encoding(x)\n",
    "\n",
    "        return self.mlp(x)[0]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        #loaders = [self.dataloader_ref] + [get_coords_dataloader(img) for img in imgs[1:]]\n",
    "        \n",
    "        return get_coords_dataloader(self.img)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return get_coords_dataloader(self.img)\n",
    "\n",
    "    def positional_encoding(self, input): # [B,...,N]\n",
    "        L = self.L\n",
    "        shape = input.shape\n",
    "        freq = 2**torch.arange(L,dtype=torch.float32).to(input.device)*np.pi # [L]\n",
    "        spectrum = input[...,None]*freq # [B,...,N,L]\n",
    "        sin,cos = spectrum.sin(),spectrum.cos() # [B,...,N,L]\n",
    "        input_enc = torch.stack([sin,cos],dim=-2) # [B,...,N,2,L]\n",
    "        input_enc = input_enc.view(*shape[:-1],-1) # [B,...,2NL]\n",
    "        \n",
    "        # coarse-to-fine: smoothly mask positional encoding for BARF\n",
    "        if self.barf_c2f:\n",
    "            # set weights for different frequency bands\n",
    "            start,end = 0,self.trainer.max_epochs\n",
    "            progress = self.current_epoch\n",
    "      \n",
    "            alpha = (progress-start)/(end-start)*L\n",
    "            k = torch.arange(L,dtype=torch.float32,device=input.device)\n",
    "            weight = (1-(alpha-k).clamp_(min=0,max=1).mul_(np.pi).cos_())/2\n",
    "            # apply weights\n",
    "            shape = input_enc.shape\n",
    "            input_enc = (input_enc.view(-1,L)*weight).view(*shape)\n",
    "            \n",
    "        return input_enc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        \n",
    "        C,H,W = self.img_GT.size()\n",
    "        x,y = batch\n",
    "        #x_euc = x/x[:,2:]\n",
    "        #y_hat = self(x_euc[:,:2])*self.mask\n",
    "        #loss = self.loss(y_hat, y)\n",
    "        #self.log(f'L_{0}', loss.item())\n",
    "        grid = rearrange(x[:,:2], '(H W) C -> H W C', H=H,W=W).unsqueeze(0) # (1, H, W, 2)\n",
    "        \n",
    "        #losses = [loss]\n",
    "        losses =[]\n",
    "\n",
    "\n",
    "        for i,img in enumerate(self.imgs):\n",
    "            \n",
    "            \n",
    "            T = self.homographies[i]                \n",
    "            \n",
    "            x_hom = (T(x.T)).T\n",
    "            x_euc = x_hom/x_hom[:,2:] # normalize homogeneous coordinates\n",
    "\n",
    "            y_hat = self(x_euc[:,:2]) # I(H(x))\n",
    "            y_hat = rearrange(y_hat, '(H W) C -> C H W', H=H,W=W).unsqueeze(0) # (1, H, W, 3)\n",
    "            y = F.grid_sample(img.unsqueeze(0), grid, align_corners=True)\n",
    "            \n",
    "            loss_i = self.loss(y_hat, y)\n",
    "            #loss += loss_i\n",
    "            losses.append(loss_i)\n",
    "            self.log(f'L_{i}', loss_i.item())\n",
    "\n",
    "            \n",
    "            H_loss = self.H_loss(T.H.detach(), self.homographies_GT[i].H.detach())\n",
    "            self.log(f'H{i}', H_loss.item())\n",
    "\n",
    "            \n",
    "        \n",
    "        losses = sum(losses)\n",
    "        self.log('loss', losses.item())\n",
    "        return losses\n",
    "\n",
    "    def render_image(self, T):\n",
    "        \n",
    "        C,H,W = self.img.size()\n",
    "        x = create_meshgrid(H,W).squeeze().to(self.device)\n",
    "        \n",
    "        ones = torch.ones((H,W,1)).to(self.device)\n",
    "        x = torch.concat([x,ones], dim=2)\n",
    "        x = rearrange(x,'H W C -> (H W) C')\n",
    "\n",
    "        x_hom = (T(x.T)).T\n",
    "        x_euc = x_hom/x_hom[:,2:]\n",
    "        y = self(x_euc[:,:2])\n",
    "\n",
    "        y = rearrange(y, '(H W) C -> C H W ', H=H,W=W)    \n",
    "\n",
    "        return y\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \n",
    "        if self.current_epoch % 10 == 0:\n",
    "            results = []\n",
    "            for i,T in enumerate(self.homographies):\n",
    "                y = self.render_image(T)\n",
    "                results.append(y)\n",
    "\n",
    "                frame = rearrange(y, 'C H W -> H W C')    \n",
    "                frame = frame.detach().cpu().numpy()\n",
    "                frame = 255*frame\n",
    "                frame = frame.astype(np.uint8)[:,:,::-1]\n",
    "                if i == 0:\n",
    "                    self.out.write(frame)\n",
    "            show(results)\n",
    "            show(self.imgs)\n",
    "            \n",
    "            patches = utils.draw_patches(results[0], self.homographies)\n",
    "            patches_GT = utils.draw_patches(self.img_GT, self.homographies_GT)\n",
    "            show([patches,patches_GT])\n",
    "            plt.show()\n",
    "            \n",
    "#    def on_after_backward(self):\n",
    "#        # example to inspect gradient information in tensorboard\n",
    "#        if self.trainer.global_step % 25 == 0:  # don't make the tf file huge\n",
    "#            params = self.state_dict()\n",
    "#            for k, v in params.items():\n",
    "#                grads = v\n",
    "#                name = k\n",
    "#                if name.startswith(\"homographies\"):\n",
    "#                    print(name)\n",
    "#                    print(grads, v.grad)\n",
    "\n",
    "                #self.logger.log_histogram(tag=\"grads\", values=grads, global_step=self.trainer.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "img = read_image(\"baboon.png\", torchvision.io.ImageReadMode.RGB)/255.\n",
    "\n",
    "\n",
    "img_numpy = rearrange(img*255,'C H W -> H W C')\n",
    "img_numpy = img_numpy.numpy().astype(np.uint8)\n",
    "T, w, corners_H = utils.get_random_Warp()\n",
    "\n",
    "C,H,W = img.size()\n",
    "\n",
    "img_warps = list(zip(*[utils.get_random_Patch(img) for _ in range(5)]))\n",
    "warps = list(img_warps[0])\n",
    "Hs = list(img_warps[1])\n",
    "print(Hs)\n",
    "#plt.imshow(img_poly)\n",
    "show(list(img_warps[0]))\n",
    "show(utils.draw_patches(img, Hs))\n",
    "\n",
    "K = 120\n",
    "img_ref = img.clone()\n",
    "img_mask = torch.ones_like(img)\n",
    "img_mask[:,:K,:]= 0\n",
    "img_mask[:,-K:,:]= 0\n",
    "img_mask[:,:,:K]= 0\n",
    "img_mask[:,:,-K:]= 0\n",
    "\n",
    "img_mask = torch.ones_like(img_ref)\n",
    "img_mask[:,:K,:]= 0\n",
    "img_mask[:,-K:,:]= 0\n",
    "img_mask[:,:,:K]= 0\n",
    "img_mask[:,:,-K:]= 0\n",
    "\n",
    "img_ref = img_ref*img_mask\n",
    "warps = [img_ref]+warps\n",
    "img_mask = rearrange(img,'c H W -> (H W) c')\n",
    "\n",
    "show(warps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMET_ML_PROJECT = \"barf\"\n",
    "torch.cuda.empty_cache()\n",
    "experiment_name = \"BARF\"\n",
    "    \n",
    "\n",
    "comet_logger = CometLogger(\n",
    "    api_key=\"tMEjeyq5M7v1IPRCvS5fyGyuo\",\n",
    "    workspace=\"semjon\", # Optional\n",
    "    project_name= COMET_ML_PROJECT, # Optional\n",
    "    # rest_api_key=os.environ[\"COMET_REST_KEY\"], \n",
    "    #save_dir='./segmentation',\n",
    "    experiment_name=experiment_name, # Optional,\n",
    "    #display_summary_level = 0\n",
    ")\n",
    "\n",
    "imgs = [img.cuda() for img in warps]\n",
    "Hs = [Homography().cuda()]+[H.cuda() for H in Hs]\n",
    "\n",
    "model = BARF_PL(imgs, img_mask, img_GT=img, H_GT=Hs, pos_enc=True, barf_c2f=True).cuda()\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", logger=comet_logger,log_every_n_steps=1, max_epochs=3000)\n",
    "trainer.fit(model)\n",
    "model.out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.zeros(8)\n",
    "\n",
    "w[0] = 0.25\n",
    "w[1] = 0.25\n",
    "\n",
    "w[5] = 0.7\n",
    "w[4] = -0.5*w[5]\n",
    "\n",
    "H = Homography(w)\n",
    "\n",
    "show(utils.draw_patches(img, [H]))\n",
    "show(utils.get_Patch(img, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Apply Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = torch.tensor([[1.0, 0, 0.5],\n",
    "                 [0, 1.0, 0.5],\n",
    "                 [0, 0, 1]]).to(model.device)\n",
    "H_inv = torch.linalg.inv(H)\n",
    "\n",
    "C,H,W = model.img.size()\n",
    "x = create_meshgrid(H,W).squeeze().to(model.device)\n",
    "ones = torch.ones((H,W,1)).to(model.device)\n",
    "x_hom = torch.concat([x,ones], dim=2)\n",
    "x_hom = rearrange(x_hom,'H W C -> (H W) C')\n",
    "\n",
    "x_hom = (H_inv@x_hom.T).T\n",
    "\n",
    "x_euc = x_hom/x_hom[:,2:]\n",
    "y = model(x_euc[:,:2])\n",
    "y = rearrange(y, '(H W) C -> C H W ', H=H,W=W)    \n",
    "show([model.img,y])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
